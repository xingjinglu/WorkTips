{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38eef717-7658-4431-9ea5-e22be46e8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db2a76e-f31d-429b-b4fb-7a77772ddcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "(2, 3)\n",
      "(2, 1)\n",
      "[<tf.Variable 'linear/dense/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[0.9032683],\n",
      "       [1.2881179],\n",
      "       [1.6729671]], dtype=float32)>, <tf.Variable 'linear/dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.38484937], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 21:15:10.826654: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-17 21:15:10.826758: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# x[2][3], y[2][1]\n",
    "x = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "y = tf.constant([[10.0], [20.0]])\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "class Linear(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            units = 1,\n",
    "            activation = None,\n",
    "            kernel_initializer = tf.zeros_initializer(),\n",
    "            bias_initializer = tf.zeros_initializer()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def call(self, input):\n",
    "        output = self.dense(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "# \n",
    "model = Linear()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-3)\n",
    "\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    \n",
    "    optimizer.apply_gradients(grads_and_vars = zip(grads, model.variables))\n",
    "\n",
    "print(model.variables)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ad658-15e2-4bf4-a799-67892b62ea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61e5ce8d-33f9-4bd1-ae5d-cfed0f270671",
   "metadata": {},
   "source": [
    "# tf.keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395d6b29-548e-430c-9bf1-1482da4c96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis = -1)\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis = -1)\n",
    "        self.train_label = self.train_label.astype(np.int32)\n",
    "        self.test_label = self.test_label.astype(np.int32)\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "        \n",
    "    def get_batch(self, batch_size):\n",
    "        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ced7a8-2361-4149-81ef-2a84b58fac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220f99d-9068-4d32-b377-e0598b74bc35",
   "metadata": {},
   "source": [
    "## 3.4 tf RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af423bf4-9a21-449d-bc70-79f05c9032bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 4.039315\n",
      "batch 1: loss 4.020144\n",
      "batch 2: loss 3.991930\n",
      "batch 3: loss 3.955172\n",
      "batch 4: loss 3.909860\n",
      "batch 5: loss 3.831239\n",
      "batch 6: loss 3.598962\n",
      "batch 7: loss 3.638101\n",
      "batch 8: loss 3.156896\n",
      "batch 9: loss 3.159657\n",
      "batch 10: loss 2.905585\n",
      "batch 11: loss 3.192379\n",
      "batch 12: loss 3.442448\n",
      "batch 13: loss 3.281109\n",
      "batch 14: loss 3.084947\n",
      "batch 15: loss 3.427345\n",
      "batch 16: loss 3.124683\n",
      "batch 17: loss 3.114635\n",
      "batch 18: loss 3.088225\n",
      "batch 19: loss 3.056967\n",
      "batch 20: loss 3.068408\n",
      "batch 21: loss 3.369570\n",
      "batch 22: loss 2.984977\n",
      "batch 23: loss 2.845366\n",
      "batch 24: loss 2.999393\n",
      "batch 25: loss 2.947476\n",
      "batch 26: loss 3.012032\n",
      "batch 27: loss 3.350656\n",
      "batch 28: loss 3.118740\n",
      "batch 29: loss 3.130414\n",
      "batch 30: loss 3.051334\n",
      "batch 31: loss 2.775728\n",
      "batch 32: loss 3.151231\n",
      "batch 33: loss 3.394035\n",
      "batch 34: loss 2.893868\n",
      "batch 35: loss 2.909874\n",
      "batch 36: loss 3.261985\n",
      "batch 37: loss 3.158598\n",
      "batch 38: loss 3.042449\n",
      "batch 39: loss 3.030560\n",
      "batch 40: loss 2.900105\n",
      "batch 41: loss 3.009262\n",
      "batch 42: loss 3.116396\n",
      "batch 43: loss 2.878636\n",
      "batch 44: loss 2.922879\n",
      "batch 45: loss 2.954194\n",
      "batch 46: loss 2.772514\n",
      "batch 47: loss 2.787428\n",
      "batch 48: loss 2.808262\n",
      "batch 49: loss 2.988116\n",
      "batch 50: loss 3.305238\n",
      "batch 51: loss 2.926498\n",
      "batch 52: loss 3.209011\n",
      "batch 53: loss 3.113753\n",
      "batch 54: loss 2.933599\n",
      "batch 55: loss 3.060902\n",
      "batch 56: loss 3.168673\n",
      "batch 57: loss 2.976637\n",
      "batch 58: loss 2.891388\n",
      "batch 59: loss 3.188957\n",
      "diversity 0.200000: \n",
      "diversity 0.500000: \n",
      "diversity 1.000000: \n",
      "diversity 1.200000: \n",
      "t.-asdnhesi.inmjuehgapn iaybr  l sye:ini\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        path = tf.keras.utils.get_file('nietzsche.txt',\n",
    "                                       origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            self.raw_text = f.read().lower()\n",
    "        \n",
    "        self.chars = sorted(list(set(self.raw_text)))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        # indice list of text\n",
    "        self.text = [self.char_indices[c] for c in self.raw_text]\n",
    "    \n",
    "    def get_batch(self, seq_length, batch_size):\n",
    "        seq = []\n",
    "        next_char = []\n",
    "        for i in range(batch_size):\n",
    "            index = np.random.randint(0, len(self.text) - seq_length)\n",
    "            seq.append(self.text[index:index+seq_length])\n",
    "            next_char.append(self.text[index+seq_length])\n",
    "        return np.array(seq), np.array(next_char) # [batch_size, seq_length], [num_batch]\n",
    "\n",
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, num_chars, batch_size, seq_length):\n",
    "        super().__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.cell = tf.keras.layers.LSTMCell(units=256)\n",
    "        self.dense = tf.keras.layers.Dense(units = self.num_chars)\n",
    "    \n",
    "    def call(self, inputs, from_logits = False):\n",
    "        # [batch_size, seq_length, num_chars]\n",
    "        inputs = tf.one_hot(inputs, depth=self.num_chars)\n",
    "        state = self.cell.get_initial_state(batch_size=self.batch_size, dtype = tf.float32)\n",
    "        for t in range(self.seq_length):\n",
    "            output, state = self.cell(inputs[:, t, :], state)\n",
    "        logits = self.dense(output)\n",
    "        if from_logits:\n",
    "            return logits\n",
    "        else:\n",
    "            return tf.nn.softmax(logits)\n",
    "    \n",
    "    # predict\n",
    "    \n",
    "    def predict(self, inputs, temperature=1.):\n",
    "        batch_size, _ = tf.shape(inputs)\n",
    "        logits = self(inputs, from_logits=True)\n",
    "        prob = tf.nn.softmax(logits / temperature).numpy()\n",
    "        return np.array([np.random.choice(self.num_chars, p=prob[i, :])\n",
    "                     for i in range(batch_size.numpy())])\n",
    "    \n",
    "\n",
    "num_batches = 60\n",
    "seq_length = 40\n",
    "batch_size = 50\n",
    "learning_rate = 1e-3\n",
    "data_loader = DataLoader()\n",
    "model = RNN(num_chars=len(data_loader.chars), batch_size=batch_size, seq_length=seq_length)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(seq_length, batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "X_, _ = data_loader.get_batch(seq_length, 1)\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    X = X_\n",
    "    print(\"diversity %f: \" % diversity)\n",
    "\n",
    "\n",
    "\n",
    "for t in range(40):\n",
    "    y_pred = model.predict(X, diversity)\n",
    "    print(data_loader.indices_char[y_pred[0]], end='', flush=True)\n",
    "    x = np.concatenate([X[:, 1:], np.expand_dims(y_pred, axis=1)], axis=-1)\n",
    "print(\"\\n\")\n",
    "\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a25a8-a035-461e-92fa-0257d44fb8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fac331-2745-4bd5-a33f-bf295bf1adcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'hello tensorflow, this test case tf.io.read', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with open(\"test_read.txt\", \"w\") as f:\n",
    "    f.write(\"hello tensorflow, this test case tf.io.read\")\n",
    "out=tf.io.read_file(\"test_read.txt\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5f9d0-0813-4ad0-ae17-739b7e00f1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a319a75a-7f2d-4160-b78f-8b3b30fe3435",
   "metadata": {},
   "source": [
    "## 3.5 RL case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb180eb-1c66-4596-b991-51072d33467f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 实例化一个游戏环境，参数为游戏名称\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCartPole-v1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 初始化环境，获得初始状态\u001b[39;00m\n\u001b[1;32m      8\u001b[0m state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/registration.py:676\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake\u001b[39m(\u001b[38;5;28mid\u001b[39m: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/registration.py:520\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec(path)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# Construct the environment\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/registration.py:139\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentry_point(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Make the environment aware of which spec it came from.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/registration.py:55\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Type:\n\u001b[1;32m     54\u001b[0m     mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/classic_control/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcartpole\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CartPoleEnv\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmountain_car\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MountainCarEnv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontinuous_mountain_car\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Continuous_MountainCarEnv\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Union\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygame'"
     ]
    }
   ],
   "source": [
    "# pip install gym\n",
    "import gym\n",
    "\n",
    "# 实例化一个游戏环境，参数为游戏名称\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# 初始化环境，获得初始状态\n",
    "state = env.reset()\n",
    "while True:\n",
    "    env.render()\n",
    "    action = model.predict(state)\n",
    "    \n",
    "    # 让环境执行动作，获得执行完动作的的下一个状态，动作的奖励，游戏是否已经结束及额外信息\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ff78e-bef2-45c3-bef1-b0a54f880f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868f5e9-0bd8-4ba8-af87-d5204dbec69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
